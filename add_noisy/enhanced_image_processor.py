#!/usr/bin/env python3
"""
enhanced_image_processor.py
---------------------------
æ•´åˆçš„å›¾åƒå¤„ç†è„šæœ¬ï¼Œæ”¯æŒå¤šç§å›¾åƒå¢å¼ºå’Œçº¹ç†å åŠ åŠŸèƒ½ã€‚

æ ¸å¿ƒç®—æ³•ï¼š
1. æ‹‰ä¸çº¹ç†ç”Ÿæˆå’Œå åŠ  (æ¥è‡ª brushed_render.py)
2. å›¾åƒç»†èŠ‚å¢å¼º (æ¥è‡ª photo_enhancer.py)
   - CLAHE è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
   - é«˜é€šæ»¤æ³¢
   - éé”åŒ–æ©æ¨¡é”åŒ–
   - åˆæˆçº¹ç†å åŠ 
3. é«˜æ–¯å™ªå£°æ·»åŠ 
4. ç»“æ„åŒ–æ¤’ç›å™ªå£°æ·»åŠ 

æ”¯æŒåŠŸèƒ½ï¼š
- å•æ–‡ä»¶æˆ–æ‰¹é‡æ–‡ä»¶å¤¹å¤„ç†
- å¯é€‰çš„æ©ç åŒºåŸŸå¤„ç†
- å¤šç§çº¹ç†æ–¹å‘é€‰æ‹©
- å¤šç§å™ªå£°æ¨¡å¼ç»„åˆä½¿ç”¨

ç¤ºä¾‹ï¼š
    python enhanced_image_processor.py input_folder output_folder --mode gaussian_noise
    python enhanced_image_processor.py input.jpg output.jpg --mode structured_salt_pepper_noise
    python enhanced_image_processor.py input_folder output_folder --mode enhance
    python enhanced_image_processor.py input_folder output_folder --mode combined
    python enhanced_image_processor.py input_folder output_folder --mode gaussian_noise,enhance
"""

import cv2
import numpy as np
import argparse
from pathlib import Path
import os


# ==================== æ‹‰ä¸çº¹ç†ç®—æ³• (æ¥è‡ª brushed_render.py) ==================== #

def brushed_noise(shape, direction="vertical", length=40, width=1, intensity=45):
    """
    ç”Ÿæˆå•å‘æ‹‰ä¸çº¹ç†
    
    Args:
        shape: å›¾åƒå°ºå¯¸ (H, W) æˆ– (H, W, C)
        direction: "vertical" æˆ– "horizontal"
        length: æ¡çº¹æ‹‰ä¼¸é•¿åº¦
        width: æ¡çº¹å®½åº¦/ç²—ç»†ï¼Œ>1 è¶Šç²—
        intensity: å™ªå£°å¼ºåº¦
    """
    h, w = shape[:2]
    noise = np.random.randn(h, w).astype(np.float32) * intensity

    # è¿åŠ¨æ¨¡ç³Šå·ç§¯æ ¸
    if direction == "vertical":
        ksize = (length, width)
    else:  # horizontal
        ksize = (width, length)

    kernel = np.ones(ksize, np.float32) / (ksize[0] * ksize[1])
    brushed = cv2.filter2D(noise, -1, kernel, borderType=cv2.BORDER_REFLECT)

    brushed = cv2.normalize(brushed, None, 0, 255, cv2.NORM_MINMAX)
    return cv2.merge([brushed.astype(np.uint8)] * 3)


def overlay_brush(base_rgb, brush_rgb, alpha=0.22, mask=None):
    """
    å åŠ æ‹‰ä¸çº¹ç†åˆ°åŸå›¾
    
    Args:
        base_rgb: åŸºç¡€å›¾åƒ (RGB)
        brush_rgb: çº¹ç†å›¾åƒ (RGB)
        alpha: å åŠ é€æ˜åº¦ 0-1
        mask: 0-255 ç°åº¦å›¾ï¼Œç™½è‰²åŒºåŸŸæ‰å åŠ ï¼›é»˜è®¤ä¸ºå…¨å›¾å åŠ 
    """
    brush_resized = cv2.resize(brush_rgb, (base_rgb.shape[1], base_rgb.shape[0]))

    if mask is None:
        out = cv2.addWeighted(base_rgb, 1.0, brush_resized, alpha, 0)
    else:
        mask_f = (mask.astype(float) / 255.0)[..., None]  # HÃ—WÃ—1
        out = base_rgb * (1 - alpha * mask_f) + brush_resized * (alpha * mask_f)

    return np.clip(out, 0, 255).astype(np.uint8)


# ==================== å›¾åƒå¢å¼ºç®—æ³• (æ¥è‡ª photo_enhancer.py) ==================== #

def apply_clahe(image_rgb, clip_limit=2.5, tile_grid_size=(8, 8)):
    """
    åœ¨LABè‰²å½©ç©ºé—´ä¸­ä½¿ç”¨CLAHEå¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦
    """
    lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)

    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    l_eq = clahe.apply(l)

    merged = cv2.merge((l_eq, a, b))
    return cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)


def high_pass_filter(image_rgb, radius=5):
    """
    é€šè¿‡é«˜æ–¯æ¨¡ç³Šå‡æ³•æå–é«˜é¢‘ç»†èŠ‚
    """
    blurred = cv2.GaussianBlur(image_rgb, (radius * 2 + 1, radius * 2 + 1), 0)
    return cv2.subtract(image_rgb, blurred)


def unsharp_mask(image_rgb, strength=1.0, blur_size=3):
    """
    ç»å…¸éé”åŒ–æ©æ¨¡ï¼šimage + (image - blur) * strength
    """
    blurred = cv2.GaussianBlur(image_rgb, (blur_size * 2 + 1, blur_size * 2 + 1), 0)
    return cv2.addWeighted(image_rgb, 1 + strength, blurred, -strength, 0)


def generate_texture_overlay(shape, scale=20, intensity=40):
    """
    ç”Ÿæˆåˆæˆçº¿æ¡/æ¡çº¹çº¹ç†å±‚
    """
    h, w, _ = shape
    noise = np.random.randn(h, w) * intensity

    # æ·»åŠ æ–¹å‘æ€§æ¡çº¹
    for i in range(h):
        noise[i] += (i % scale) - scale / 2

    texture = np.clip(noise, 0, 255).astype(np.uint8)
    return cv2.merge([texture] * 3)  # å¤åˆ¶åˆ°3ä¸ªé€šé“


def blend_texture(base_rgb, texture_rgb, alpha=0.15):
    """
    å°†çº¹ç†æ··åˆåˆ°åŸºç¡€å›¾åƒä¸Š
    """
    texture_resized = cv2.resize(texture_rgb, (base_rgb.shape[1], base_rgb.shape[0]))
    blended = cv2.addWeighted(base_rgb, 1.0, texture_resized, alpha, 0)
    return blended


def add_structured_salt_pepper_noise(image, amount=0.01, block_size=2, seed=123, max_perturbation=16):
    """
    æ·»åŠ ç»“æ„åŒ–éšæœºå™ªå£°ï¼Œæ¯ä¸ªå™ªç‚¹æ˜¯ block_size Ã— block_size çš„å½©è‰²éšæœºæ–¹å—ã€‚

    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (H, W, 3), np.uint8
        amount: æ›¿æ¢åŒºåŸŸæ¯”ä¾‹ï¼ˆæ€»åƒç´ å æ¯”ï¼‰
        block_size: æ¯ä¸ªæ‰°åŠ¨å—çš„è¾¹é•¿ï¼ˆé»˜è®¤2ï¼‰
        seed: å¯é€‰éšæœºç§å­

    è¿”å›:
        æ·»åŠ å™ªå£°åçš„å›¾åƒ (np.uint8)
    """
    if seed is not None:
        np.random.seed(seed)

    image = image.astype(np.float32)
    h, w, c = image.shape
    output = image.copy()

    total_blocks = int((h * w * amount) / (block_size * block_size))

    for _ in range(total_blocks):
        x = np.random.randint(0, w - block_size)
        y = np.random.randint(0, h - block_size)

        noise_block = np.random.randint(0, 256, size=(block_size, block_size, 3), dtype=np.uint8)
        output[y:y+block_size, x:x+block_size] = noise_block

    # è®¡ç®—æ‰°åŠ¨ delta
    delta = output - image
    max_val = np.max(np.abs(delta))

    if max_val > max_perturbation:
        scale = max_perturbation / max_val
        delta = delta * scale
        output = image + delta

    return np.clip(output, 0, 255).astype(np.uint8)

def add_gaussian_noise(image, mean=0, std=10, seed=123, max_perturbation=16):
    """
    æ·»åŠ é«˜æ–¯å™ªå£°
    """
    if seed is not None:
        np.random.seed(seed)

    # å™ªå£°ç”Ÿæˆä¸º float32
    noise = np.random.normal(mean, std, image.shape).astype(np.float32)

    # è£å‰ªå™ªå£°èŒƒå›´ï¼Œç¡®ä¿ä¸ä¼šè¶…å‡º max_perturbation
    noise = np.clip(noise, -max_perturbation, max_perturbation)

    # è½¬ä¸º float åŠ å™ªå£°
    noisy = image.astype(np.float32) + noise

    # è½¬å›åˆæ³•åƒç´ èŒƒå›´ + uint8
    return np.clip(noisy, 0, 255).astype(np.uint8) 


def add_high_variance_noise(image, max_perturbation=16, seed=123):
    """
    æ·»åŠ  Â±max_perturbation å‡åŒ€æ‰°åŠ¨ï¼Œå…·æœ‰æœ€å¤§æ–¹å·®ä¸”ä¸ä¼šæº¢å‡ºã€‚

    è¿”å›æ‰°åŠ¨åçš„ uint8 å›¾åƒã€‚
    """
    if seed is not None:
        np.random.seed(seed)

    image = image.astype(np.float32)
    noise = np.random.uniform(
        low=-max_perturbation,
        high=+max_perturbation,
        size=image.shape
    )
    perturbed = image + noise
    return np.clip(perturbed, 0, 255).astype(np.uint8)

def add_max_variance_binary_noise(image, max_perturbation=16, seed=123):
    """
    æ·»åŠ  Â±max_perturbation çš„äºŒå€¼éšæœºæ‰°åŠ¨ï¼Œæ–¹å·®æœ€å¤§ï¼Œä½†è§†è§‰å¾ˆæ¿€è¿›ã€‚
    """
    if seed is not None:
        np.random.seed(seed)

    image = image.astype(np.float32)
    choices = np.random.choice(
        [-max_perturbation, +max_perturbation],
        size=image.shape
    )
    perturbed = image + choices
    return np.clip(perturbed, 0, 255).astype(np.uint8)



def enhance_image_with_texture(
    image_rgb,
    clahe_clip=2.5,
    clahe_grid=(8, 8),
    hp_radius=5,
    unsharp_strength=1.0,
    texture_scale=20,
    texture_intensity=40,
    texture_alpha=0.15,
    max_perturbation=None,
):
    """
    å›¾åƒå¢å¼ºæµæ°´çº¿ï¼Œè¿è¡Œæ‰€æœ‰å¢å¼ºæ­¥éª¤
    """
    # 1. CLAHE
    clahe_img = apply_clahe(image_rgb, clahe_clip, clahe_grid)

    # 2. é«˜é€šæ»¤æ³¢ç»†èŠ‚
    high_pass = high_pass_filter(clahe_img, hp_radius)
    enhanced = cv2.addWeighted(clahe_img, 1.0, high_pass, 1.0, 0)

    # 3. éé”åŒ–æ©æ¨¡
    sharpened = unsharp_mask(enhanced, unsharp_strength)

    # 4. çº¹ç†å åŠ 
    texture = generate_texture_overlay(sharpened.shape, texture_scale, texture_intensity)
    final = blend_texture(sharpened, texture, texture_alpha)

    # 5. æ‰°åŠ¨é™åˆ¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if max_perturbation is not None:
        perturbation = final.astype(np.int16) - image_rgb.astype(np.int16)
        perturbation = np.clip(perturbation, -max_perturbation, max_perturbation)
        final = image_rgb.astype(np.int16) + perturbation

    return np.clip(final, 0, 255).astype(np.uint8)

# def enhance_image_with_texture(
#     image_rgb,
#     clahe_clip=2.5,
#     clahe_grid=(8, 8),
#     hp_radius=5,
#     unsharp_strength=1.0,
#     texture_scale=20,
#     texture_intensity=40,
#     texture_alpha=0.15,
#     max_perturbation=16  # ä»¥åƒç´ å€¼å®šä¹‰ï¼Œä¾‹å¦‚16ä»£è¡¨ Â±16/255
# ):
#     """Pipeline wrapper that runs all enhancement steps with structured delta tracking and perturbation bounding."""

#     def normalize(delta):
#         norm = np.linalg.norm(delta)
#         return delta / norm if norm != 0 else delta

#     def enforce_max_perturbation(orig_img, final_img, max_perturbation):
#         """Scale perturbation globally to stay within Â±max_perturbation (in pixel units)."""
#         orig_f = orig_img.astype(np.float32) / 255.0
#         final_f = final_img.astype(np.float32) / 255.0
#         delta = final_f - orig_f
#         max_val = np.max(np.abs(delta))
#         epsilon = max_perturbation / 255.0
#         if max_val > epsilon:
#             scale = epsilon / max_val
#             final_f = orig_f + delta * scale
#         return np.clip(final_f * 255.0, 0, 255).astype(np.uint8)

#     image = image_rgb.astype(np.float32)

#     # 1. CLAHE
#     clahe_img = apply_clahe(image_rgb, clahe_clip, clahe_grid).astype(np.float32)
#     delta1 = clahe_img - image

#     # 2. High-pass details
#     high_pass = high_pass_filter(clahe_img, hp_radius).astype(np.float32)
#     enhanced = cv2.addWeighted(clahe_img, 1.0, high_pass, 1.0, 0).astype(np.float32)
#     delta2 = enhanced - image

#     # 3. Unsharp masking
#     sharpened = unsharp_mask(enhanced, unsharp_strength).astype(np.float32)
#     delta3 = sharpened - enhanced

#     # 4. Texture overlay
#     texture = generate_texture_overlay(sharpened.shape, texture_scale, texture_intensity).astype(np.float32)
#     final = blend_texture(sharpened, texture, texture_alpha).astype(np.float32)
#     delta4 = final - sharpened

#     # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
#     print(f"delta1 max: {np.max(np.abs(delta1)):.2f}, delta2: {np.max(np.abs(delta2)):.2f}, delta3: {np.max(np.abs(delta3)):.2f}, delta4: {np.max(np.abs(delta4)):.2f}")

#     # æœ€ç»ˆæ‰°åŠ¨é™åˆ¶
#     if max_perturbation is not None:
#         final = enforce_max_perturbation(image_rgb, final, max_perturbation)
        
#     return final

def strong_highfreq(img_f, eps, chess_weight=0.4, jitter_weight=0.4, uniform_weight=0.2, chess_scale=8):
    """
    å¼ºé«˜é¢‘æ‰°åŠ¨ï¼ŒåŒ…å«å¤šç§é«˜é¢‘æ¨¡å¼
    
    å‚æ•°:
        img_f: è¾“å…¥å›¾åƒ (uint8)
        eps: æœ€å¤§æ‰°åŠ¨å¼ºåº¦ (åƒç´ å€¼)
        chess_weight: æ£‹ç›˜æ ¼æ¨¡å¼æƒé‡
        jitter_weight: åƒç´ æŠ–åŠ¨æƒé‡  
        uniform_weight: å‡åŒ€å™ªå£°æƒé‡
        chess_scale: æ£‹ç›˜æ ¼å°ºåº¦ (è¶Šå°è¶Šå¯†é›†)
    """
    # å°†è¾“å…¥è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ–åˆ° [0,1]
    img_f = img_f.astype(np.float32) / 255.0
    
    h,w = img_f.shape[:2]
    
    # 1. æ£‹ç›˜æ ¼æ¨¡å¼ - å¢å¼ºé«˜é¢‘ç»“æ„
    pattern = ((np.indices((h,w)).sum(0)&(chess_scale-1))*(2//chess_scale)*2-1)[...,None]  # æ›´å¯†é›†çš„æ£‹ç›˜æ ¼
    noise1 = chess_weight * eps/255.0 * pattern

    # 2. åƒç´ æŠ–åŠ¨ - å¢å¼ºè¾¹ç¼˜é«˜é¢‘
    dx = np.random.randint(-2,3,size=(h,w))  # å¢åŠ æŠ–åŠ¨èŒƒå›´
    dy = np.random.randint(-2,3,size=(h,w))
    X,Y = np.meshgrid(np.arange(w),np.arange(h))
    mapx = (X+dx).clip(0,w-1).astype(np.float32)
    mapy = (Y+dy).clip(0,h-1).astype(np.float32)
    jitter = cv2.remap(img_f, mapx, mapy, cv2.INTER_LINEAR) - img_f
    noise2 = jitter_weight * eps/255.0 * np.sign(jitter)   # æ–¹å‘æ€§ä¿ç•™

    # 3. é«˜é¢‘å‡åŒ€å™ªå£°
    noise3 = uniform_weight * eps/255.0 * np.random.uniform(-1,1,size=img_f.shape)
    
    # 4. æ·»åŠ æ‹‰æ™®æ‹‰æ–¯è¾¹ç¼˜å¢å¼º
    gray = cv2.cvtColor((img_f*255).astype(np.uint8), cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0
    laplacian = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    laplacian = cv2.normalize(laplacian, None, -1, 1, cv2.NORM_MINMAX)
    edge_noise = np.repeat(laplacian[:, :, np.newaxis], 3, axis=2) * 0.3 * eps/255.0

    # ç»„åˆæ‰€æœ‰å™ªå£°
    delta = np.clip(noise1 + noise2 + noise3 + edge_noise, -eps/255.0, eps/255.0)
    result = np.clip(img_f + delta, 0, 1)
    
    # è½¬æ¢å› uint8
    return (result * 255.0).astype(np.uint8)



def stylised_needles(img_rgb, eps=16/255, alpha=0.75, seed=0):
    """
    é’ˆçŠ¶é£æ ¼åŒ–æ‰°åŠ¨ï¼Œå¢å¼ºé«˜é¢‘è¾¹ç¼˜ä¿¡æ¯
    
    å‚æ•°:
        img_rgb: RGB è¾“å…¥å›¾åƒ
        eps: æ‰°åŠ¨å¼ºåº¦ (å½’ä¸€åŒ–åˆ° [0,1])
        alpha: å åŠ å¼ºåº¦
        seed: éšæœºç§å­
    """
    np.random.seed(seed)
    img = img_rgb.astype(np.float32) / 255.0
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0

    # --- 1) XDoG ç»†çº¿ï¼ˆç™½ / é»‘ï¼‰- å¢å¼ºé«˜é¢‘è¾¹ç¼˜æ£€æµ‹
    blur1 = cv2.GaussianBlur(gray, (0,0), 0.5)  # å‡å°æ¨¡ç³ŠåŠå¾„ï¼Œå¢å¼ºé«˜é¢‘
    blur2 = cv2.GaussianBlur(gray, (0,0), 1.0)  # å‡å°æ¨¡ç³ŠåŠå¾„
    dog   = blur1 - 2.0 * blur2  # å¢å¼ºå¯¹æ¯”åº¦
    xdog  = (dog > 0.02).astype(np.float32)   # é™ä½é˜ˆå€¼ï¼Œæ•è·æ›´å¤šè¾¹ç¼˜
    xneg  = (dog < -0.02).astype(np.float32)  # é™ä½é˜ˆå€¼
    edge  = (xdog - xneg)[...,None]           # -1,0,1

    # --- 2) å¢åŠ å½©è‰²çº¿æ®µæ¯”ä¾‹ï¼Œå¢å¼ºè§†è§‰å†²å‡»
    h,w = gray.shape
    ang = np.mod(np.arctan2(
                 cv2.Sobel(gray,cv2.CV_32F,0,1,ksize=3),
                 cv2.Sobel(gray,cv2.CV_32F,1,0,ksize=3)
            ) + np.pi, 2*np.pi) / (2*np.pi)    # 0~1
    hsv = np.dstack([ang, np.ones_like(ang), np.ones_like(ang)])
    color = cv2.cvtColor((hsv*255).astype(np.uint8), cv2.COLOR_HSV2RGB).astype(np.float32)/255  # ä¿®æ­£ä¸ºRGB
    keep = (np.random.rand(h,w) < 0.15)[...,None]  # å¢åŠ åˆ° 15% å½©è‰²çº¿æ®µ
    colour_edge = edge * (keep*color + (1-keep))   # ç™½/å½©/é»‘

    # --- 3) å åŠ å¹¶è£å‰ªåˆ° Lâˆ â‰¤ Îµ
    overlay = (colour_edge*2 - 1) * eps          # [-Îµ,Îµ]
    adv = np.clip(img + alpha*overlay, 0, 1)
    delta = np.clip(adv - img, -eps, eps)
    adv   = (img + delta) * 255
    return adv.astype(np.uint8)

def generate_split_inducing_perturbation(
    image,
    edge_strength=14,
    perlin_scale=0.5,
    perlin_intensity=8,
    uniform_strength=6,
    max_perturbation=16,
    seed=123
):
    """
    æ·»åŠ èƒ½ä¿ƒä½¿ Gaussian Splatting åˆ†è£‚çš„å¤šæºæ‰°åŠ¨ï¼ˆè¾¹ç¼˜ + çº¹ç† + å‡åŒ€ï¼‰ã€‚

    å‚æ•°:
        image: è¾“å…¥å›¾åƒ (H, W, 3), np.uint8
        edge_strength: è¾¹ç¼˜å¢å¼ºæ‰°åŠ¨å¼ºåº¦
        perlin_scale: Perlin çº¹ç†é¢‘ç‡ï¼ˆè¶Šå¤§è¶Šå¯†ï¼‰
        perlin_intensity: Perlin çº¹ç†æ‰°åŠ¨å¼ºåº¦
        uniform_strength: å…¨å›¾å‡åŒ€æ‰°åŠ¨çš„æœ€å¤§å¹…åº¦
        max_perturbation: æœ€ç»ˆæ‰°åŠ¨ä¸Šé™ï¼ˆåƒç´ å€¼å•ä½ï¼Œé»˜è®¤ Â±16ï¼‰
        seed: éšæœºç§å­

    è¿”å›:
        æ‰°åŠ¨å›¾åƒï¼ˆnp.uint8ï¼‰ï¼Œæœ€å¤§æ‰°åŠ¨å—é™äº max_perturbation
    """

    def enforce_max_perturbation(orig_img, final_img, max_pert):
        """å°† final ä¸ orig çš„æ‰°åŠ¨é™åˆ¶åœ¨ Â±max_perturbation"""
        orig_f = orig_img.astype(np.float32) / 255.0
        final_f = final_img.astype(np.float32) / 255.0
        delta = final_f - orig_f
        max_val = np.max(np.abs(delta))
        epsilon = max_pert / 255.0
        if max_val > epsilon:
            scale = epsilon / max_val
            final_f = orig_f + delta * scale
        return np.clip(final_f * 255.0, 0, 255).astype(np.uint8)

    if seed is not None:
        np.random.seed(seed)

    image = image.astype(np.float32)
    h, w, _ = image.shape
    result = image.copy()

    # === 1. è¾¹ç¼˜å¢å¼ºæ‰°åŠ¨ ===
    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)
    edges = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    edges = cv2.normalize(edges, None, -1, 1, cv2.NORM_MINMAX)
    edge_noise = np.repeat(edges[:, :, np.newaxis], 3, axis=2) * edge_strength
    result += edge_noise

    # === 2. Perlin çº¹ç†æ‰°åŠ¨ ===
    try:
        import noise  # pip install noise
        perlin = np.zeros((h, w), dtype=np.float32)
        for y in range(h):
            for x in range(w):
                perlin[y, x] = noise.pnoise2(x * perlin_scale, y * perlin_scale, repeatx=1024, repeaty=1024)
        perlin = (perlin - perlin.min()) / (perlin.max() - perlin.min()) * 2 - 1  # [-1, 1]
        perlin_rgb = np.repeat(perlin[:, :, np.newaxis], 3, axis=2)
        result += perlin_rgb * perlin_intensity
    except ImportError:
        print("Perlin noise skipped: please install 'noise' package via `pip install noise`")

    # === 3. å…¨å›¾å‡åŒ€æ‰°åŠ¨ ===
    uniform_noise = np.random.uniform(-uniform_strength, uniform_strength, size=image.shape)
    result += uniform_noise

    # === æœ€ç»ˆæ‰°åŠ¨å¹…åº¦å‹ç¼©åˆ° Â±max_perturbation ===
    result = enforce_max_perturbation(image, result, max_perturbation)

    return result.astype(np.uint8)

def ultra_highfreq_attack(img_rgb, eps=16, seed=123):
    """
    è¶…å¼ºé«˜é¢‘æ”»å‡»ï¼Œä¸“é—¨é’ˆå¯¹ Gaussian Splatting çš„é«˜é¢‘æ•æ„Ÿç‰¹æ€§
    
    å‚æ•°:
        img_rgb: RGB è¾“å…¥å›¾åƒ
        eps: æœ€å¤§æ‰°åŠ¨å¼ºåº¦ (åƒç´ å€¼)
        seed: éšæœºç§å­
    """
    np.random.seed(seed)
    img = img_rgb.astype(np.float32) / 255.0
    h, w, c = img.shape
    
    # 1. é«˜é¢‘æ£‹ç›˜æ ¼æ¨¡å¼ (4x4 åƒç´ å—)
    chess_4x4 = np.zeros((h, w, c))
    for i in range(0, h, 4):
        for j in range(0, w, 4):
            val = ((i//4 + j//4) % 2) * 2 - 1  # Â±1
            chess_4x4[i:i+4, j:j+4] = val
    
    # 2. é«˜é¢‘æ¡çº¹æ¨¡å¼
    stripes = np.zeros((h, w, c))
    for i in range(h):
        for j in range(w):
            stripes[i, j] = (i % 8 < 4) * 2 - 1  # å‚ç›´æ¡çº¹
    
    # 3. é«˜é¢‘ç‚¹é˜µæ¨¡å¼
    dots = np.zeros((h, w, c))
    for i in range(0, h, 6):
        for j in range(0, w, 6):
            if (i//6 + j//6) % 2 == 0:
                dots[i:i+3, j:j+3] = 1
            else:
                dots[i:i+3, j:j+3] = -1
    
    # 4. è¾¹ç¼˜å¢å¼º
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0
    edges = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    edges = cv2.normalize(edges, None, -1, 1, cv2.NORM_MINMAX)
    edge_pattern = np.repeat(edges[:, :, np.newaxis], 3, axis=2)
    
    # 5. ç»„åˆæ‰€æœ‰é«˜é¢‘æ¨¡å¼
    highfreq_pattern = (
        0.3 * chess_4x4 + 
        0.2 * stripes + 
        0.2 * dots + 
        0.3 * edge_pattern
    )
    
    # 6. æ·»åŠ éšæœºé«˜é¢‘å™ªå£°
    random_noise = np.random.uniform(-1, 1, (h, w, c))
    
    # 7. æœ€ç»ˆæ‰°åŠ¨
    perturbation = (highfreq_pattern + 0.1 * random_noise) * eps / 255.0
    perturbation = np.clip(perturbation, -eps/255.0, eps/255.0)
    
    result = np.clip(img + perturbation, 0, 1)
    return (result * 255.0).astype(np.uint8)


# ==================== æ•´åˆå¤„ç†å‡½æ•° ==================== #

def process_single_image(input_path, output_path, args, mask=None):
    """
    å¤„ç†å•å¼ å›¾ç‰‡
    
    Args:
        input_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        args: å‘½ä»¤è¡Œå‚æ•°
        mask: å¯é€‰çš„æ©ç å›¾åƒ
    """
    # è¯»å–åŸå›¾å¹¶è½¬ RGB
    bgr = cv2.imread(str(input_path))
    if bgr is None:
        print(f"âš ï¸  æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶: {input_path}")
        return False
    
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    result_rgb = rgb.copy()

    # è§£ææ¨¡å¼åˆ—è¡¨
    modes = [mode.strip() for mode in args.mode.split(',')]
    
    # æŒ‰é¡ºåºåº”ç”¨æ¯ä¸ªæ¨¡å¼
    for mode in modes:
        if mode == "gaussian_noise":
            result_rgb = add_gaussian_noise(
                result_rgb, 
                mean=args.gaussian_mean, 
                std=args.gaussian_std, 
                seed=args.gaussian_seed, 
                max_perturbation=args.gaussian_max_perturbation
            )
            print(f"  â• åº”ç”¨é«˜æ–¯å™ªå£° (std={args.gaussian_std})")

        elif mode == "structured_salt_pepper_noise":
            result_rgb = add_structured_salt_pepper_noise(
                result_rgb, 
                amount=args.salt_pepper_amount, 
                block_size=args.salt_pepper_block_size, 
                seed=args.salt_pepper_seed,
                max_perturbation=args.max_perturbation
            )
            print(f"  â• åº”ç”¨ç»“æ„åŒ–æ¤’ç›å™ªå£° (amount={args.salt_pepper_amount})")

        elif mode == "strong_highfreq":
            result_rgb = strong_highfreq(
                result_rgb,
                eps=args.max_perturbation
            )
            print(f"  â• åº”ç”¨å¼ºé«˜é¢‘æ‰°åŠ¨ (eps={args.max_perturbation})")

        elif mode == "enhance":
            result_rgb = enhance_image_with_texture(
                result_rgb, 
                clahe_clip=args.clahe, 
                clahe_grid=(args.clahe_grid, args.clahe_grid), 
                hp_radius=args.hp_radius, 
                unsharp_strength=args.unsharp, 
                texture_scale=args.texture_scale, 
                texture_intensity=args.texture_intensity, 
                texture_alpha=args.texture_alpha, 
                max_perturbation=args.max_perturbation
            )
            print(f"  â• åº”ç”¨å›¾åƒå¢å¼º")
        
        elif mode == "enhance_with_pepper":
            result_rgb = enhance_image_with_texture(
                result_rgb, 
                clahe_clip=args.clahe, 
                clahe_grid=(args.clahe_grid, args.clahe_grid), 
                hp_radius=args.hp_radius, 
                unsharp_strength=args.unsharp, 
                texture_scale=args.texture_scale, 
                texture_intensity=args.texture_intensity, 
                texture_alpha=args.texture_alpha, 
                max_perturbation=args.max_perturbation
            )
            print(f"  â• åº”ç”¨å›¾åƒå¢å¼º")

            result_rgb = add_structured_salt_pepper_noise(
                result_rgb, 
                amount=args.salt_pepper_amount, 
                block_size=args.salt_pepper_block_size, 
                seed=args.salt_pepper_seed,
                max_perturbation=args.max_perturbation
            )
            print(f"  â• åº”ç”¨ç»“æ„åŒ–æ¤’ç›å™ªå£° (amount={args.salt_pepper_amount})")
            
        elif mode == "high_variance_noise":
            result_rgb = add_high_variance_noise(
                result_rgb, 
                max_perturbation=args.max_perturbation, 
                seed=123
            )
            print(f"  â• åº”ç”¨é«˜æ–¹å·®å™ªå£° (max_perturbation={args.max_perturbation})")

        elif mode == "max_variance_binary_noise":
            result_rgb = add_max_variance_binary_noise(
                result_rgb, 
                max_perturbation=args.max_perturbation, 
                seed=123
            )
            print(f"  â• åº”ç”¨æœ€å¤§æ–¹å·®äºŒå€¼å™ªå£° (max_perturbation={args.max_perturbation})")

        elif mode == "split_inducing_perturbation":
            result_rgb = generate_split_inducing_perturbation(
                result_rgb,
                edge_strength=14,
                perlin_scale=0.5,
                perlin_intensity=8,
                uniform_strength=6,
                max_perturbation=args.max_perturbation,
                seed=123
            )
            print(f"  â• åº”ç”¨åˆ†è£‚è¯±å¯¼æ‰°åŠ¨ (max_perturbation={args.max_perturbation})")
        elif mode == "stylised_needles":
            result_rgb = stylised_needles(
                result_rgb,
                eps=args.max_perturbation/255.0,
                alpha=0.75,
                seed=123
            )
            print(f"  â• åº”ç”¨é’ˆçŠ¶é£æ ¼åŒ–æ‰°åŠ¨ (eps={args.max_perturbation})")

        elif mode == "brush":
            # æ‹‰ä¸çº¹ç†æ¨¡å¼
            brush = brushed_noise(
                result_rgb.shape,
                direction=args.dir,
                length=args.length,
                width=args.width,
                intensity=args.intensity,
            )
            result_rgb = overlay_brush(result_rgb, brush, alpha=args.alpha, mask=mask)
            print(f"  â• åº”ç”¨æ‹‰ä¸çº¹ç†")

        elif mode == "combined":
            # ç»„åˆæ¨¡å¼ï¼šå…ˆå¢å¼ºï¼Œå†å åŠ æ‹‰ä¸çº¹ç†
            result_rgb = enhance_image_with_texture(
                result_rgb,
                clahe_clip=args.clahe,
                clahe_grid=(args.clahe_grid, args.clahe_grid),
                hp_radius=args.hp_radius,
                unsharp_strength=args.unsharp,
                texture_scale=args.texture_scale,
                texture_intensity=args.texture_intensity,
                texture_alpha=args.texture_alpha,
                max_perturbation=args.max_perturbation,
            )
            
            brush = brushed_noise(
                result_rgb.shape,
                direction=args.dir,
                length=args.length,
                width=args.width,
                intensity=args.intensity,
            )
            result_rgb = overlay_brush(result_rgb, brush, alpha=args.alpha, mask=mask)
            print(f"  â• åº”ç”¨ç»„åˆæ¨¡å¼ï¼ˆå¢å¼º+æ‹‰ä¸çº¹ç†ï¼‰")
        
        else:
            print(f"âŒ ä¸æ”¯æŒçš„å¤„ç†æ¨¡å¼: {mode}")
            return False

    # ä¿å­˜ç»“æœ
    output_path.parent.mkdir(parents=True, exist_ok=True)
    cv2.imwrite(str(output_path), cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR))
    return True


def get_image_files(input_path):
    """
    è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶
    """
    supported_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
    
    if input_path.is_file():
        # å•æ–‡ä»¶æ¨¡å¼
        if input_path.suffix.lower() in supported_extensions:
            return [input_path]
        else:
            print(f"âš ï¸  ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {input_path}")
            return []
    
    elif input_path.is_dir():
        # æ–‡ä»¶å¤¹æ¨¡å¼
        image_files = []
        for ext in supported_extensions:
            image_files.extend(input_path.glob(f"*{ext}"))
            image_files.extend(input_path.glob(f"*{ext.upper()}"))
        return sorted(image_files)
    
    else:
        print(f"âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return []


# ==================== å‘½ä»¤è¡Œæ¥å£ ==================== #

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    p = argparse.ArgumentParser(description="æ•´åˆçš„å›¾åƒå¤„ç†è„šæœ¬ï¼Œæ”¯æŒå¤šç§å™ªå£°å’Œå¢å¼ºæ¨¡å¼")
    
    # åŸºæœ¬å‚æ•°
    p.add_argument("input", help="è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„")
    p.add_argument("output", help="è¾“å‡ºå›¾ç‰‡è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„")
    p.add_argument("--mode", 
                   default="gaussian_noise", 
                   help="å¤„ç†æ¨¡å¼ï¼Œæ”¯æŒå•ä¸ªæ¨¡å¼æˆ–ç»„åˆæ¨¡å¼ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰: gaussian_noise, structured_salt_pepper_noise, enhance, brush, combined (default: gaussian_noise)")
    p.add_argument("--mask", help="å¯é€‰æ©ç å›¾ (ç™½è‰²åŒºåŸŸå¤„ç†)")
    
    # æ‹‰ä¸çº¹ç†å‚æ•°
    p.add_argument("--dir", choices=["vertical", "horizontal"],
                   default="vertical", help="çº¹ç†æ–¹å‘ (default: vertical)")
    p.add_argument("--length", type=int, default=40,
                   help="çº¹ç†æ¡çº¹é•¿åº¦ (default: 40)")
    p.add_argument("--width", type=int, default=10,
                   help="çº¹ç†æ¡çº¹å®½åº¦ (default: 10)")
    p.add_argument("--intensity", type=int, default=45,
                   help="çº¹ç†å™ªå£°å¼ºåº¦ (default: 45)")
    p.add_argument("--alpha", type=float, default=0.22,
                   help="å åŠ é€æ˜åº¦ 0-1 (default: 0.22)")
    
    # é«˜æ–¯å™ªå£°å‚æ•°
    p.add_argument("--gaussian-mean", type=float, default=0,
                   help="é«˜æ–¯å™ªå£°å‡å€¼ (default: 0)")
    p.add_argument("--gaussian-std", type=float, default=10,
                   help="é«˜æ–¯å™ªå£°æ ‡å‡†å·® (default: 10)")
    p.add_argument("--gaussian-seed", type=int, default=123,
                   help="é«˜æ–¯å™ªå£°éšæœºç§å­ (default: 123)")
    p.add_argument("--gaussian-max-perturbation", type=float, default=16,
                   help="é«˜æ–¯å™ªå£°æœ€å¤§æ‰°åŠ¨ (default: 16)")
    
    # ç»“æ„åŒ–æ¤’ç›å™ªå£°å‚æ•°
    p.add_argument("--salt-pepper-amount", type=float, default=0.01,
                   help="æ¤’ç›å™ªå£°æ¯”ä¾‹ 0-1 (default: 0.01)")
    p.add_argument("--salt-pepper-block-size", type=int, default=2,
                   help="æ¤’ç›å™ªå£°å—å¤§å° (default: 4)")
    p.add_argument("--salt-pepper-seed", type=int, default=123,
                   help="æ¤’ç›å™ªå£°éšæœºç§å­ (default: 123)")
    
    # å›¾åƒå¢å¼ºå‚æ•°
    p.add_argument("--clahe", type=float, default=2.5,
                   help="CLAHE clip limit (default: 2.5)")
    p.add_argument("--clahe-grid", type=int, default=8,
                   help="CLAHE tile grid size (default: 8)")
    p.add_argument("--hp-radius", type=int, default=5,
                   help="é«˜é€šæ»¤æ³¢åŠå¾„ (default: 5)")
    p.add_argument("--unsharp", type=float, default=1.0,
                   help="éé”åŒ–æ©æ¨¡å¼ºåº¦ (default: 1.0)")
    p.add_argument("--texture-scale", type=int, default=20,
                   help="çº¹ç†æ¡çº¹å°ºåº¦ (default: 20)")
    p.add_argument("--texture-intensity", type=int, default=40,
                   help="çº¹ç†å™ªå£°å¼ºåº¦ (default: 40)")
    p.add_argument("--texture-alpha", type=float, default=0.15,
                   help="çº¹ç†æ··åˆé€æ˜åº¦ (default: 0.15)")
    p.add_argument("--max-perturbation", type=float, default=None,
                   help="æœ€å¤§æ‰°åŠ¨ (default: None)")
    
    return p.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    input_path = Path(args.input)
    output_path = Path(args.output)
    
    # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶
    image_files = get_image_files(input_path)
    
    if not image_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶")
        return
    
    # è¯»å–æ©ç ï¼ˆå¦‚æœæä¾›ï¼‰
    mask = None
    if args.mask:
        mask = cv2.imread(args.mask, 0)
        if mask is None:
            print(f"âš ï¸  æ— æ³•è¯»å–æ©ç æ–‡ä»¶: {args.mask}")
    
    # å¤„ç†å›¾ç‰‡
    success_count = 0
    total_count = len(image_files)
    
    print(f"ğŸ“ å¼€å§‹å¤„ç† {total_count} å¼ å›¾ç‰‡...")
    print(f"ğŸ¯ å¤„ç†æ¨¡å¼: {args.mode}")
    
    for i, img_path in enumerate(image_files, 1):
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if input_path.is_file():
            # å•æ–‡ä»¶æ¨¡å¼
            out_path = output_path
        else:
            # æ–‡ä»¶å¤¹æ¨¡å¼ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            rel_path = img_path.relative_to(input_path)
            out_path = output_path / rel_path
        
        print(f"ğŸ”„ å¤„ç† ({i}/{total_count}): {img_path.name}")
        
        if process_single_image(img_path, out_path, args, mask):
            success_count += 1
            print(f"âœ… å·²ä¿å­˜: {out_path}")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {img_path.name}")
    
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{total_count} å¼ å›¾ç‰‡")


if __name__ == "__main__":
    main() 